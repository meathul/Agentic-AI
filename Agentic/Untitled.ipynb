{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e20fce09-1c3f-4122-8c66-fde23e0e5292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Using cached langchain-0.3.25-py3-none-any.whl.metadata (7.8 kB)\n",
      "Requirement already satisfied: openai in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (1.78.0)\n",
      "Collecting langchain-core<1.0.0,>=0.3.58 (from langchain)\n",
      "  Downloading langchain_core-0.3.65-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n",
      "  Using cached langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting langsmith<0.4,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.3.45-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain) (2.11.3)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading sqlalchemy-2.0.41-cp311-cp311-macosx_10_9_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Collecting tenacity!=8.4.0,<10.0.0,>=8.1.0 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<1.0.0,>=0.3.58->langchain)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.17->langchain)\n",
      "  Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: anyio in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: certifi in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (3.10)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.4.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.2.3-cp311-cp311-macosx_11_0_universal2.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: sniffio in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /opt/anaconda3/envs/llms/lib/python3.11/site-packages (from openai) (4.67.1)\n",
      "Using cached langchain-0.3.25-py3-none-any.whl (1.0 MB)\n",
      "Downloading langchain_core-0.3.65-py3-none-any.whl (438 kB)\n",
      "Using cached jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading langsmith-0.3.45-py3-none-any.whl (363 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading sqlalchemy-2.0.41-cp311-cp311-macosx_10_9_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
      "Downloading greenlet-3.2.3-cp311-cp311-macosx_11_0_universal2.whl (270 kB)\n",
      "Installing collected packages: tenacity, packaging, jsonpatch, greenlet, SQLAlchemy, requests-toolbelt, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "\u001b[2K  Attempting uninstall: packaging\n",
      "\u001b[2K    Found existing installation: packaging 25.0\n",
      "\u001b[2K    Uninstalling packaging-25.0:\n",
      "\u001b[2K      Successfully uninstalled packaging-25.0\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/10\u001b[0m [langchain]10\u001b[0m [langchain]core]\n",
      "\u001b[1A\u001b[2KSuccessfully installed SQLAlchemy-2.0.41 greenlet-3.2.3 jsonpatch-1.33 langchain-0.3.25 langchain-core-0.3.65 langchain-text-splitters-0.3.8 langsmith-0.3.45 packaging-24.2 requests-toolbelt-1.0.0 tenacity-9.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "caff65e3-aba8-4b94-957d-b310b51fe63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import Tool\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "def calculator_tool(x):\n",
    "    import re\n",
    "    x = x.lower().strip()\n",
    "    numbers = list(map(float, re.findall(r\"\\d+(?:\\.\\d+)?\", x)))\n",
    "\n",
    "    if \"add\" in x or \"+\" in x or (len(numbers) == 2 and \"then\" not in x):\n",
    "        return str(sum(numbers))\n",
    "    elif \"subtract\" in x or \"-\" in x:\n",
    "        return str(numbers[0] - numbers[1])\n",
    "    elif \"multiply\" in x or \"*\" in x:\n",
    "        return str(numbers[0] * numbers[1])\n",
    "    elif \"divide\" in x or \"/\" in x:\n",
    "        return str(numbers[0] / numbers[1])\n",
    "    return \"Unsupported operation\"\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad8247ae-5621-4877-8e25-399060fc34cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def web_scrape_limited(input_str):\n",
    "    try:\n",
    "        import re\n",
    "\n",
    "        parts = input_str.strip().split()\n",
    "        url = next((p for p in parts if p.startswith(\"http\")), None)\n",
    "        if url:\n",
    "            url = url.strip(\"'\\\"\")  # strip any trailing quotes\n",
    "\n",
    "        lines = int(re.findall(r'\\d+', input_str)[-1])\n",
    "\n",
    "        if not url:\n",
    "            return \"No valid URL found in input.\"\n",
    "\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            return f\"Failed to fetch page, status code: {response.status_code}\"\n",
    "\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        paragraphs = soup.find_all('p')\n",
    "        text = '\\n'.join(p.get_text() for p in paragraphs)\n",
    "        limited_text = \"\\n\".join(text.splitlines()[:lines])\n",
    "        return limited_text if limited_text else \"No lines found.\"\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error during scraping: {str(e)}\"\n",
    "\n",
    "\n",
    "\n",
    "calculator = Tool(\n",
    "    name=\"Calculator\",\n",
    "    func=calculator_tool,\n",
    "    description=\"Performs basic arithmetic operations like add, subtract, multiply, divide. Input should be natural language like 'Add 100 and 5'.\"\n",
    ")\n",
    "web_scraper_limited = Tool(\n",
    "    name=\"Web Scraper\",\n",
    "    func=web_scrape_limited,\n",
    "    description=\"Scrapes the specified number of lines from a web page. Input should be like 'Scrape 105 lines from https://example.com'\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "76ec0538-375a-4339-8d48-2d215cbb16c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4\", temperature=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bd9a8a9a-ac92-42be-9ac8-89a19c23a811",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "agent = initialize_agent(\n",
    "    tools=[calculator, web_scraper_limited],\n",
    "    llm=llm,\n",
    "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "76076a53-8613-4eea-a214-5824ef14c888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mFirst, I need to add 100 and 5 using the calculator tool.\n",
      "Action: Calculator\n",
      "Action Input: 'Add 100 and 5'\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m105.0\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that I have the sum, I need to scrape 105 lines from the specified website.\n",
      "Action: Web Scraper\n",
      "Action Input: 'Scrape 105 lines from https://edwarddonner.com'\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3mI’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (very amateur) and losing myself in Hacker News, nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of Nebula.io. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt, acquired in 2021.\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve patented our matching model, and our award-winning platform has happy customers and tons of press coverage. Connect with me for more!\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tType your email…\t\t\t\t\t\t\t\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\t\t\t\t\t\t\t\tSubscribe\t\t\t\t\t\t\t\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI have successfully scraped 105 lines from the website.\n",
      "Final Answer: I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (very amateur) and losing myself in Hacker News, nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of Nebula.io. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt, acquired in 2021.\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve patented our matching model, and our award-winning platform has happy customers and tons of press coverage. Connect with me for more!\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tType your email…\t\t\t\t\t\t\t\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\t\t\t\t\t\t\t\tSubscribe\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (very amateur) and losing myself in Hacker News, nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of Nebula.io. We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt, acquired in 2021.\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve patented our matching model, and our award-winning platform has happy customers and tons of press coverage. Connect with me for more!\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tType your email…\t\t\t\t\t\t\t\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\t\t\t\t\t\t\t\tSubscribe\n"
     ]
    }
   ],
   "source": [
    "response = agent.run(\n",
    "    \"Add 100 and 5, then scrape that many lines from https://edwarddonner.com\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d934123-9cd6-42ba-9a64-a5ab9debda92",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
